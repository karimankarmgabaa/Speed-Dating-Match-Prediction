{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3634ccaa",
   "metadata": {},
   "source": [
    "<h1 style=\"property:value;color:Coral;font-size:300%;text-align:center; \">CISC-873-DM-F22-A2</h1> \n",
    "<h3 style=\"property:value;color:Coral;font-size:200%;text-align:center; \">Speed Dating Match Prediction</h3> \n",
    "<h5 style=\"property:value;color:Sienna;font-size:150%; \">Kariman Karm Mohamed Mousaa </h5> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "878bc432",
   "metadata": {},
   "source": [
    "#### 1- Define the problem. What is the input? What is the output? What data mining function is required? What could be the challenges? What is the impact? What is an ideal solution?\n",
    "ans:\n",
    "* problem:we are going to predict the outcome of a specific speed dating session based on the profile of two people and their information.\n",
    "* input:for train process 192 columns  191 training and 1 target values (match).\n",
    "* output:y_hat for Match, we will prediction if the two person  will match or not.\n",
    "* data mining function: Classification\n",
    "* the challenges: feature selection choise the feature.\n",
    "* the impact: there many steps for cleaning and ideas \n",
    "* an ideal solution: drop all column have many null values.\n",
    "----------------------------------------------------------------------------\n",
    "#### 2- Why a simple linear regression model (without any activation function) is not good for classification task, compared to Perceptron/Logistic regression?\n",
    "ans: \n",
    "* a simple linear regression model (without any activation function) is not good for classification task:\n",
    "  - Linear Regression deals with continuous values whereas classification problems mandate discrete values.\n",
    "  - it is regarding the shift in threshold value when new data points are added.\n",
    "* Perceptron/Logistic regression:They're both applying regression by estimating the parameters of the same logistic-transformed model. According to the properties of convex functions, the values of the parameters will be the same any way you choose to estimate them but \n",
    "  - Logistic regression models a function of the mean of a Bernoulli distribution as a linear equation (the mean being equal to the probability p of a Bernoulli event). By using the logit link as a function of the mean (p), the logarithm of the odds (log-odds) can be derived analytically and used as the response of a so-called generalised linear model. On top of prediction, this allows to interpret the model in causal inference. This is something that you cannot achieve with a linear Perceptron.\n",
    "  - The Perceptron, takes the inverse logit (logistic) function of wx, and doesn't use probabilistic assumptions for neither the model nor its parameter. Online training will give exactly the same estimates for the model weights/parameters, but we won't be able to interpret them in causal inference due to the lack of p-values, confidence intervals, and well, an underlying probability model.\n",
    "---------------------------------------------------------------------------------\n",
    "#### 3- What's a decision tree and how it is different to a logistic regression model?\n",
    "ans:\n",
    "* a decision tree:it is a type of supervised machine learning used to categorize or make predictions based on how a previous set of questions were answered. \n",
    "* Decision Boundaries:Decision Trees bisect the space into smaller and smaller regions, whereas Logistic Regression fits a single line to divide the space exactly into two.\n",
    "----------------------------------------------------------------------------\n",
    "#### 4- What's the difference between grid search and random search?\n",
    "ans \n",
    "* In Grid Search, we try every combination of a preset list of values of the hyper-parameters and choose the best combination based on the cross validation score.\n",
    "* Random search tries random combinations of a range of values (we have to define the number iterations). It is good in testing a wide range of values and normally it reaches a very good combination very fast, but the problem that it doesn’t guarantee to give the best parameters combination.\n",
    "--------------------------------------------------------------------------------\n",
    "#### 5- What's the difference between bayesian search and random search?\n",
    "ans:\n",
    "* Bayesian optimization is a sequential model-based optimization (SMBO) algorithm that uses the results from the previous iteration to decide the next hyperparameter value candidates.it creates a probabilistic model, mapping hyperparameters to a probability of a score on the objective function. For more mathematical details.\n",
    "*  Random search tries random combinations of a range of values (we have to define the number iterations). It is good in testing a wide range of values and normally it reaches a very good combination very fast, but the problem that it doesn’t guarantee to give the best parameters combination.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5f97d1b",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f7242b61",
   "metadata": {},
   "source": [
    "### Import Libararies and Loading data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "e5dd5d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Libararies\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "3c684a42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>idg</th>\n",
       "      <th>condtn</th>\n",
       "      <th>wave</th>\n",
       "      <th>round</th>\n",
       "      <th>position</th>\n",
       "      <th>positin1</th>\n",
       "      <th>order</th>\n",
       "      <th>partner</th>\n",
       "      <th>pid</th>\n",
       "      <th>...</th>\n",
       "      <th>attr3_3</th>\n",
       "      <th>sinc3_3</th>\n",
       "      <th>intel3_3</th>\n",
       "      <th>fun3_3</th>\n",
       "      <th>amb3_3</th>\n",
       "      <th>attr5_3</th>\n",
       "      <th>sinc5_3</th>\n",
       "      <th>intel5_3</th>\n",
       "      <th>fun5_3</th>\n",
       "      <th>amb5_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>14</td>\n",
       "      <td>12</td>\n",
       "      <td>372.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>63.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>331.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>20</td>\n",
       "      <td>18</td>\n",
       "      <td>13.0</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>200.0</td>\n",
       "      <td>...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>20</td>\n",
       "      <td>6</td>\n",
       "      <td>6.0</td>\n",
       "      <td>20</td>\n",
       "      <td>17</td>\n",
       "      <td>357.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>18</td>\n",
       "      <td>8</td>\n",
       "      <td>368.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>20</td>\n",
       "      <td>17</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>204.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>18</td>\n",
       "      <td>15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>94.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>21</td>\n",
       "      <td>10</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>278.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>21</td>\n",
       "      <td>13</td>\n",
       "      <td>13.0</td>\n",
       "      <td>15</td>\n",
       "      <td>11</td>\n",
       "      <td>283.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 191 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   gender  idg  condtn  wave  round  position  positin1  order  partner  \\\n",
       "0       0    3       2    14     18         2       2.0     14       12   \n",
       "1       1   14       1     3     10         2       NaN      8        8   \n",
       "2       1   14       1    13     10         8       8.0     10       10   \n",
       "3       1   38       2     9     20        18      13.0      6        7   \n",
       "4       1   24       2    14     20         6       6.0     20       17   \n",
       "5       0    3       2    14     18         2       2.0     18        8   \n",
       "6       1    6       2     9     20        17      16.0      2       11   \n",
       "7       0    7       2     4     18        15       NaN      1        1   \n",
       "8       0   29       2    11     21        10      10.0      3        6   \n",
       "9       0    7       2    11     21        13      13.0     15       11   \n",
       "\n",
       "     pid  ...  attr3_3  sinc3_3  intel3_3  fun3_3  amb3_3  attr5_3  sinc5_3  \\\n",
       "0  372.0  ...      NaN      NaN       NaN     NaN     NaN      NaN      NaN   \n",
       "1   63.0  ...      6.0      8.0       8.0     7.0     8.0      NaN      NaN   \n",
       "2  331.0  ...      NaN      NaN       NaN     NaN     NaN      NaN      NaN   \n",
       "3  200.0  ...      8.0      9.0       8.0     8.0     6.0      NaN      NaN   \n",
       "4  357.0  ...      NaN      NaN       NaN     NaN     NaN      NaN      NaN   \n",
       "5  368.0  ...      NaN      NaN       NaN     NaN     NaN      NaN      NaN   \n",
       "6  204.0  ...      NaN      NaN       NaN     NaN     NaN      NaN      NaN   \n",
       "7   94.0  ...      NaN      NaN       NaN     NaN     NaN      NaN      NaN   \n",
       "8  278.0  ...      NaN      NaN       NaN     NaN     NaN      NaN      NaN   \n",
       "9  283.0  ...      NaN      NaN       NaN     NaN     NaN      NaN      NaN   \n",
       "\n",
       "   intel5_3  fun5_3  amb5_3  \n",
       "0       NaN     NaN     NaN  \n",
       "1       NaN     NaN     NaN  \n",
       "2       NaN     NaN     NaN  \n",
       "3       NaN     NaN     NaN  \n",
       "4       NaN     NaN     NaN  \n",
       "5       NaN     NaN     NaN  \n",
       "6       NaN     NaN     NaN  \n",
       "7       NaN     NaN     NaN  \n",
       "8       NaN     NaN     NaN  \n",
       "9       NaN     NaN     NaN  \n",
       "\n",
       "[10 rows x 191 columns]"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load data \n",
    "train=pd.read_csv('train.csv')\n",
    "test=pd.read_csv('test.csv')\n",
    "#variable or id from test\n",
    "v=test['id']\n",
    "#trail 8,9,10,11 drop id from train and test\n",
    "train.drop('id',axis=1,inplace=True)\n",
    "test.drop('id',axis=1,inplace=True)\n",
    "train.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cf0808f",
   "metadata": {},
   "source": [
    "### Exploring data  and Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "77db690b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5909 entries, 0 to 5908\n",
      "Columns: 191 entries, gender to amb5_3\n",
      "dtypes: float64(173), int64(10), object(8)\n",
      "memory usage: 8.6+ MB\n"
     ]
    }
   ],
   "source": [
    "#information about train data \n",
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "00b07eb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5909, 191)"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#shape of data\n",
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "186bceba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gender         0\n",
       "idg            0\n",
       "condtn         0\n",
       "wave           0\n",
       "round          0\n",
       "            ... \n",
       "attr5_3     4496\n",
       "sinc5_3     4496\n",
       "intel5_3    4496\n",
       "fun5_3      4496\n",
       "amb5_3      4496\n",
       "Length: 191, dtype: int64"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#count the number of null in envery class\n",
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "b71e43c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#copy train data to keep our data\n",
    "df=train.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "5b59b928",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['field', 'undergra', 'mn_sat', 'tuition', 'from', 'zipcode', 'income', 'career']\n"
     ]
    }
   ],
   "source": [
    "#get list of columns, list of numerical columns and  categorical columns\n",
    "cols = df.columns\n",
    "num_cols = df._get_numeric_data().columns\n",
    "categorical_cols=[]\n",
    "for i in cols:\n",
    "    if i not in num_cols:\n",
    "        categorical_cols.append(i)\n",
    "        \n",
    "print(categorical_cols)        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c138c1ad",
   "metadata": {},
   "source": [
    "### Preprocessing for Categorical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "7a73aeb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5909 entries, 0 to 5908\n",
      "Data columns (total 8 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   field     5864 non-null   object\n",
      " 1   undergra  3467 non-null   object\n",
      " 2   mn_sat    2235 non-null   object\n",
      " 3   tuition   2544 non-null   object\n",
      " 4   from      5851 non-null   object\n",
      " 5   zipcode   5189 non-null   object\n",
      " 6   income    3047 non-null   object\n",
      " 7   career    5845 non-null   object\n",
      "dtypes: object(8)\n",
      "memory usage: 369.4+ KB\n"
     ]
    }
   ],
   "source": [
    "# information about categorial data \n",
    "df[categorical_cols].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "c34c3d12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "field         45\n",
       "undergra    2442\n",
       "mn_sat      3674\n",
       "tuition     3365\n",
       "from          58\n",
       "zipcode      720\n",
       "income      2862\n",
       "career        64\n",
       "dtype: int64"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#count the null values in categorical data\n",
    "df[categorical_cols].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "bb3a443b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop all columns have null values bigger than 2000\n",
    "df.drop(['undergra','mn_sat','tuition','income'],axis=1,inplace=True)\n",
    "test.drop(['undergra','mn_sat','tuition','income'],axis=1,inplace=True)\n",
    "#Replace the missing values with the most frequent values present in each categorical column\n",
    "df[['field','from','zipcode','career']]=df[['field','from','zipcode','career']].fillna(df[['field','from','zipcode','career']].mode().iloc[0])\n",
    "test[['field','from','zipcode','career']]=test[['field','from','zipcode','career']].fillna(test[['field','from','zipcode','career']].mode().iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "449b6944",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          964\n",
       "10,021      94\n",
       "10,027      88\n",
       "10,025      77\n",
       "10,012      31\n",
       "          ... \n",
       "560,032      3\n",
       "20,854       3\n",
       "10,803       2\n",
       "11,020       2\n",
       "20,853       2\n",
       "Name: zipcode, Length: 409, dtype: int64"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['zipcode'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "f34c7c17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       False\n",
       "1       False\n",
       "2       False\n",
       "3       False\n",
       "4       False\n",
       "        ...  \n",
       "2464     True\n",
       "2465     True\n",
       "2466     True\n",
       "2467     True\n",
       "2468     True\n",
       "Length: 2469, dtype: bool"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get duplicated in our data \n",
    "df[['field','from','zipcode','career']].duplicated()\n",
    "test[['field','from','zipcode','career']].duplicated()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "83c3a399",
   "metadata": {},
   "outputs": [],
   "source": [
    "#trail 8 ,9,10,11\n",
    "# drop duplicated in categorical data \n",
    "df[['field','from','zipcode','career']]=df[['field','from','zipcode','career']].drop_duplicates()\n",
    "test[['field','from','zipcode','career']]=test[['field','from','zipcode','career']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "7350207b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>field</th>\n",
       "      <th>from</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>career</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>158</td>\n",
       "      <td>0</td>\n",
       "      <td>232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>75</td>\n",
       "      <td>25</td>\n",
       "      <td>131</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>206</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>106</td>\n",
       "      <td>233</td>\n",
       "      <td>35</td>\n",
       "      <td>332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>23</td>\n",
       "      <td>123</td>\n",
       "      <td>269</td>\n",
       "      <td>360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5904</th>\n",
       "      <td>259</td>\n",
       "      <td>269</td>\n",
       "      <td>409</td>\n",
       "      <td>367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5905</th>\n",
       "      <td>259</td>\n",
       "      <td>269</td>\n",
       "      <td>409</td>\n",
       "      <td>367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5906</th>\n",
       "      <td>259</td>\n",
       "      <td>269</td>\n",
       "      <td>409</td>\n",
       "      <td>367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5907</th>\n",
       "      <td>259</td>\n",
       "      <td>269</td>\n",
       "      <td>409</td>\n",
       "      <td>367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5908</th>\n",
       "      <td>259</td>\n",
       "      <td>269</td>\n",
       "      <td>409</td>\n",
       "      <td>367</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5909 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      field  from  zipcode  career\n",
       "0        63   158        0     232\n",
       "1        75    25      131      80\n",
       "2       206    21        0     193\n",
       "3       106   233       35     332\n",
       "4        23   123      269     360\n",
       "...     ...   ...      ...     ...\n",
       "5904    259   269      409     367\n",
       "5905    259   269      409     367\n",
       "5906    259   269      409     367\n",
       "5907    259   269      409     367\n",
       "5908    259   269      409     367\n",
       "\n",
       "[5909 rows x 4 columns]"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#convert categorical to numerical by label encoder \n",
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "for i in ['field','from','zipcode','career']:\n",
    "    df[i]=le.fit_transform(df[i])\n",
    "    test[i]=le.fit_transform(test[i])\n",
    "df[['field','from','zipcode','career']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd551677",
   "metadata": {},
   "source": [
    "### Preprocessing for Numerical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "7bc25c50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>idg</th>\n",
       "      <th>condtn</th>\n",
       "      <th>wave</th>\n",
       "      <th>round</th>\n",
       "      <th>position</th>\n",
       "      <th>positin1</th>\n",
       "      <th>order</th>\n",
       "      <th>partner</th>\n",
       "      <th>pid</th>\n",
       "      <th>...</th>\n",
       "      <th>attr3_3</th>\n",
       "      <th>sinc3_3</th>\n",
       "      <th>intel3_3</th>\n",
       "      <th>fun3_3</th>\n",
       "      <th>amb3_3</th>\n",
       "      <th>attr5_3</th>\n",
       "      <th>sinc5_3</th>\n",
       "      <th>intel5_3</th>\n",
       "      <th>fun5_3</th>\n",
       "      <th>amb5_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5909.000000</td>\n",
       "      <td>5909.000000</td>\n",
       "      <td>5909.000000</td>\n",
       "      <td>5909.000000</td>\n",
       "      <td>5909.000000</td>\n",
       "      <td>5909.000000</td>\n",
       "      <td>4591.000000</td>\n",
       "      <td>5909.00000</td>\n",
       "      <td>5909.000000</td>\n",
       "      <td>5901.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2804.000000</td>\n",
       "      <td>2804.000000</td>\n",
       "      <td>2804.000000</td>\n",
       "      <td>2804.000000</td>\n",
       "      <td>2804.000000</td>\n",
       "      <td>1413.000000</td>\n",
       "      <td>1413.000000</td>\n",
       "      <td>1413.000000</td>\n",
       "      <td>1413.000000</td>\n",
       "      <td>1413.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.505331</td>\n",
       "      <td>17.360298</td>\n",
       "      <td>1.824843</td>\n",
       "      <td>11.347436</td>\n",
       "      <td>16.850228</td>\n",
       "      <td>9.001523</td>\n",
       "      <td>9.254846</td>\n",
       "      <td>8.91166</td>\n",
       "      <td>8.962938</td>\n",
       "      <td>283.733266</td>\n",
       "      <td>...</td>\n",
       "      <td>7.241797</td>\n",
       "      <td>8.105563</td>\n",
       "      <td>8.377318</td>\n",
       "      <td>7.644437</td>\n",
       "      <td>7.398716</td>\n",
       "      <td>6.799717</td>\n",
       "      <td>7.631989</td>\n",
       "      <td>7.944798</td>\n",
       "      <td>7.162774</td>\n",
       "      <td>7.092711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.500014</td>\n",
       "      <td>10.947542</td>\n",
       "      <td>0.380133</td>\n",
       "      <td>6.011495</td>\n",
       "      <td>4.389246</td>\n",
       "      <td>5.482368</td>\n",
       "      <td>5.611803</td>\n",
       "      <td>5.45710</td>\n",
       "      <td>5.500706</td>\n",
       "      <td>158.993002</td>\n",
       "      <td>...</td>\n",
       "      <td>1.593787</td>\n",
       "      <td>1.601011</td>\n",
       "      <td>1.459013</td>\n",
       "      <td>1.757559</td>\n",
       "      <td>1.956924</td>\n",
       "      <td>1.535768</td>\n",
       "      <td>1.498024</td>\n",
       "      <td>1.320919</td>\n",
       "      <td>1.687431</td>\n",
       "      <td>1.713729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.00000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>153.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>8.00000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>280.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>13.00000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>409.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>22.00000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>552.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 183 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            gender          idg       condtn         wave        round  \\\n",
       "count  5909.000000  5909.000000  5909.000000  5909.000000  5909.000000   \n",
       "mean      0.505331    17.360298     1.824843    11.347436    16.850228   \n",
       "std       0.500014    10.947542     0.380133     6.011495     4.389246   \n",
       "min       0.000000     1.000000     1.000000     1.000000     5.000000   \n",
       "25%       0.000000     8.000000     2.000000     7.000000    14.000000   \n",
       "50%       1.000000    16.000000     2.000000    11.000000    18.000000   \n",
       "75%       1.000000    26.000000     2.000000    15.000000    20.000000   \n",
       "max       1.000000    44.000000     2.000000    21.000000    22.000000   \n",
       "\n",
       "          position     positin1       order      partner          pid  ...  \\\n",
       "count  5909.000000  4591.000000  5909.00000  5909.000000  5901.000000  ...   \n",
       "mean      9.001523     9.254846     8.91166     8.962938   283.733266  ...   \n",
       "std       5.482368     5.611803     5.45710     5.500706   158.993002  ...   \n",
       "min       1.000000     1.000000     1.00000     1.000000     1.000000  ...   \n",
       "25%       4.000000     4.000000     4.00000     4.000000   153.000000  ...   \n",
       "50%       8.000000     9.000000     8.00000     8.000000   280.000000  ...   \n",
       "75%      13.000000    14.000000    13.00000    13.000000   409.000000  ...   \n",
       "max      22.000000    22.000000    22.00000    22.000000   552.000000  ...   \n",
       "\n",
       "           attr3_3      sinc3_3     intel3_3       fun3_3       amb3_3  \\\n",
       "count  2804.000000  2804.000000  2804.000000  2804.000000  2804.000000   \n",
       "mean      7.241797     8.105563     8.377318     7.644437     7.398716   \n",
       "std       1.593787     1.601011     1.459013     1.757559     1.956924   \n",
       "min       2.000000     2.000000     3.000000     2.000000     1.000000   \n",
       "25%       7.000000     7.000000     8.000000     7.000000     6.000000   \n",
       "50%       7.000000     8.000000     8.000000     8.000000     8.000000   \n",
       "75%       8.000000     9.000000     9.000000     9.000000     9.000000   \n",
       "max      12.000000    12.000000    12.000000    12.000000    12.000000   \n",
       "\n",
       "           attr5_3      sinc5_3     intel5_3       fun5_3       amb5_3  \n",
       "count  1413.000000  1413.000000  1413.000000  1413.000000  1413.000000  \n",
       "mean      6.799717     7.631989     7.944798     7.162774     7.092711  \n",
       "std       1.535768     1.498024     1.320919     1.687431     1.713729  \n",
       "min       2.000000     2.000000     4.000000     1.000000     1.000000  \n",
       "25%       6.000000     7.000000     7.000000     6.000000     6.000000  \n",
       "50%       7.000000     8.000000     8.000000     7.000000     7.000000  \n",
       "75%       8.000000     9.000000     9.000000     8.000000     8.000000  \n",
       "max      10.000000    10.000000    10.000000    10.000000    10.000000  \n",
       "\n",
       "[8 rows x 183 columns]"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#describe train data\n",
    "df[num_cols].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "6617970c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>idg</th>\n",
       "      <th>condtn</th>\n",
       "      <th>wave</th>\n",
       "      <th>round</th>\n",
       "      <th>position</th>\n",
       "      <th>positin1</th>\n",
       "      <th>order</th>\n",
       "      <th>partner</th>\n",
       "      <th>pid</th>\n",
       "      <th>...</th>\n",
       "      <th>attr3_3</th>\n",
       "      <th>sinc3_3</th>\n",
       "      <th>intel3_3</th>\n",
       "      <th>fun3_3</th>\n",
       "      <th>amb3_3</th>\n",
       "      <th>attr5_3</th>\n",
       "      <th>sinc5_3</th>\n",
       "      <th>intel5_3</th>\n",
       "      <th>fun5_3</th>\n",
       "      <th>amb5_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>gender</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.032132</td>\n",
       "      <td>-0.000875</td>\n",
       "      <td>-0.004192</td>\n",
       "      <td>0.017755</td>\n",
       "      <td>-0.004047</td>\n",
       "      <td>0.000410</td>\n",
       "      <td>0.009850</td>\n",
       "      <td>0.010318</td>\n",
       "      <td>-0.056275</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.150992</td>\n",
       "      <td>-0.169387</td>\n",
       "      <td>0.011476</td>\n",
       "      <td>-0.153701</td>\n",
       "      <td>-0.066626</td>\n",
       "      <td>-0.133302</td>\n",
       "      <td>-0.277085</td>\n",
       "      <td>0.080227</td>\n",
       "      <td>-0.065562</td>\n",
       "      <td>0.069091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>idg</th>\n",
       "      <td>0.032132</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.330587</td>\n",
       "      <td>0.093823</td>\n",
       "      <td>0.391918</td>\n",
       "      <td>0.164705</td>\n",
       "      <td>0.174651</td>\n",
       "      <td>0.161976</td>\n",
       "      <td>0.139034</td>\n",
       "      <td>0.088372</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011633</td>\n",
       "      <td>-0.050350</td>\n",
       "      <td>-0.060674</td>\n",
       "      <td>-0.041080</td>\n",
       "      <td>-0.005502</td>\n",
       "      <td>0.001764</td>\n",
       "      <td>-0.018915</td>\n",
       "      <td>-0.093206</td>\n",
       "      <td>-0.061079</td>\n",
       "      <td>-0.145645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>condtn</th>\n",
       "      <td>-0.000875</td>\n",
       "      <td>0.330587</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.219735</td>\n",
       "      <td>0.820898</td>\n",
       "      <td>0.331013</td>\n",
       "      <td>0.306722</td>\n",
       "      <td>0.331402</td>\n",
       "      <td>0.322467</td>\n",
       "      <td>0.218009</td>\n",
       "      <td>...</td>\n",
       "      <td>0.087388</td>\n",
       "      <td>0.044158</td>\n",
       "      <td>0.061796</td>\n",
       "      <td>0.069298</td>\n",
       "      <td>0.027447</td>\n",
       "      <td>0.077571</td>\n",
       "      <td>-0.087502</td>\n",
       "      <td>0.051449</td>\n",
       "      <td>0.106486</td>\n",
       "      <td>0.123314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wave</th>\n",
       "      <td>-0.004192</td>\n",
       "      <td>0.093823</td>\n",
       "      <td>0.219735</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.228917</td>\n",
       "      <td>0.079820</td>\n",
       "      <td>0.061166</td>\n",
       "      <td>0.093478</td>\n",
       "      <td>0.087904</td>\n",
       "      <td>0.996714</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001678</td>\n",
       "      <td>0.036948</td>\n",
       "      <td>-0.104562</td>\n",
       "      <td>0.053971</td>\n",
       "      <td>0.000520</td>\n",
       "      <td>0.092556</td>\n",
       "      <td>-0.001751</td>\n",
       "      <td>0.014611</td>\n",
       "      <td>0.088716</td>\n",
       "      <td>0.047841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>round</th>\n",
       "      <td>0.017755</td>\n",
       "      <td>0.391918</td>\n",
       "      <td>0.820898</td>\n",
       "      <td>0.228917</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.380632</td>\n",
       "      <td>0.368352</td>\n",
       "      <td>0.397952</td>\n",
       "      <td>0.390320</td>\n",
       "      <td>0.218901</td>\n",
       "      <td>...</td>\n",
       "      <td>0.094818</td>\n",
       "      <td>0.036600</td>\n",
       "      <td>0.022696</td>\n",
       "      <td>0.059530</td>\n",
       "      <td>0.013107</td>\n",
       "      <td>0.034647</td>\n",
       "      <td>-0.035242</td>\n",
       "      <td>-0.012896</td>\n",
       "      <td>0.104829</td>\n",
       "      <td>0.092951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>attr5_3</th>\n",
       "      <td>-0.133302</td>\n",
       "      <td>0.001764</td>\n",
       "      <td>0.077571</td>\n",
       "      <td>0.092556</td>\n",
       "      <td>0.034647</td>\n",
       "      <td>0.066300</td>\n",
       "      <td>0.201598</td>\n",
       "      <td>0.018610</td>\n",
       "      <td>0.002868</td>\n",
       "      <td>0.108400</td>\n",
       "      <td>...</td>\n",
       "      <td>0.858673</td>\n",
       "      <td>0.174329</td>\n",
       "      <td>0.421117</td>\n",
       "      <td>0.410789</td>\n",
       "      <td>0.235485</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.190198</td>\n",
       "      <td>0.355876</td>\n",
       "      <td>0.412403</td>\n",
       "      <td>0.194078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sinc5_3</th>\n",
       "      <td>-0.277085</td>\n",
       "      <td>-0.018915</td>\n",
       "      <td>-0.087502</td>\n",
       "      <td>-0.001751</td>\n",
       "      <td>-0.035242</td>\n",
       "      <td>0.111991</td>\n",
       "      <td>0.125594</td>\n",
       "      <td>-0.035897</td>\n",
       "      <td>-0.002601</td>\n",
       "      <td>0.021372</td>\n",
       "      <td>...</td>\n",
       "      <td>0.224796</td>\n",
       "      <td>0.608213</td>\n",
       "      <td>0.315857</td>\n",
       "      <td>0.180240</td>\n",
       "      <td>0.122856</td>\n",
       "      <td>0.190198</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.498313</td>\n",
       "      <td>0.335823</td>\n",
       "      <td>0.261307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>intel5_3</th>\n",
       "      <td>0.080227</td>\n",
       "      <td>-0.093206</td>\n",
       "      <td>0.051449</td>\n",
       "      <td>0.014611</td>\n",
       "      <td>-0.012896</td>\n",
       "      <td>0.089283</td>\n",
       "      <td>0.106791</td>\n",
       "      <td>-0.004632</td>\n",
       "      <td>0.003345</td>\n",
       "      <td>0.009585</td>\n",
       "      <td>...</td>\n",
       "      <td>0.335831</td>\n",
       "      <td>0.288062</td>\n",
       "      <td>0.683871</td>\n",
       "      <td>0.240322</td>\n",
       "      <td>0.268646</td>\n",
       "      <td>0.355876</td>\n",
       "      <td>0.498313</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.262987</td>\n",
       "      <td>0.422743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fun5_3</th>\n",
       "      <td>-0.065562</td>\n",
       "      <td>-0.061079</td>\n",
       "      <td>0.106486</td>\n",
       "      <td>0.088716</td>\n",
       "      <td>0.104829</td>\n",
       "      <td>0.135484</td>\n",
       "      <td>0.232412</td>\n",
       "      <td>0.016419</td>\n",
       "      <td>0.031795</td>\n",
       "      <td>0.096788</td>\n",
       "      <td>...</td>\n",
       "      <td>0.394979</td>\n",
       "      <td>0.160204</td>\n",
       "      <td>0.295997</td>\n",
       "      <td>0.771447</td>\n",
       "      <td>0.331533</td>\n",
       "      <td>0.412403</td>\n",
       "      <td>0.335823</td>\n",
       "      <td>0.262987</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.379768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>amb5_3</th>\n",
       "      <td>0.069091</td>\n",
       "      <td>-0.145645</td>\n",
       "      <td>0.123314</td>\n",
       "      <td>0.047841</td>\n",
       "      <td>0.092951</td>\n",
       "      <td>0.058825</td>\n",
       "      <td>0.030543</td>\n",
       "      <td>0.029174</td>\n",
       "      <td>0.050511</td>\n",
       "      <td>0.043115</td>\n",
       "      <td>...</td>\n",
       "      <td>0.194495</td>\n",
       "      <td>0.135499</td>\n",
       "      <td>0.353093</td>\n",
       "      <td>0.429332</td>\n",
       "      <td>0.619087</td>\n",
       "      <td>0.194078</td>\n",
       "      <td>0.261307</td>\n",
       "      <td>0.422743</td>\n",
       "      <td>0.379768</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>183 rows × 183 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            gender       idg    condtn      wave     round  position  \\\n",
       "gender    1.000000  0.032132 -0.000875 -0.004192  0.017755 -0.004047   \n",
       "idg       0.032132  1.000000  0.330587  0.093823  0.391918  0.164705   \n",
       "condtn   -0.000875  0.330587  1.000000  0.219735  0.820898  0.331013   \n",
       "wave     -0.004192  0.093823  0.219735  1.000000  0.228917  0.079820   \n",
       "round     0.017755  0.391918  0.820898  0.228917  1.000000  0.380632   \n",
       "...            ...       ...       ...       ...       ...       ...   \n",
       "attr5_3  -0.133302  0.001764  0.077571  0.092556  0.034647  0.066300   \n",
       "sinc5_3  -0.277085 -0.018915 -0.087502 -0.001751 -0.035242  0.111991   \n",
       "intel5_3  0.080227 -0.093206  0.051449  0.014611 -0.012896  0.089283   \n",
       "fun5_3   -0.065562 -0.061079  0.106486  0.088716  0.104829  0.135484   \n",
       "amb5_3    0.069091 -0.145645  0.123314  0.047841  0.092951  0.058825   \n",
       "\n",
       "          positin1     order   partner       pid  ...   attr3_3   sinc3_3  \\\n",
       "gender    0.000410  0.009850  0.010318 -0.056275  ... -0.150992 -0.169387   \n",
       "idg       0.174651  0.161976  0.139034  0.088372  ...  0.011633 -0.050350   \n",
       "condtn    0.306722  0.331402  0.322467  0.218009  ...  0.087388  0.044158   \n",
       "wave      0.061166  0.093478  0.087904  0.996714  ... -0.001678  0.036948   \n",
       "round     0.368352  0.397952  0.390320  0.218901  ...  0.094818  0.036600   \n",
       "...            ...       ...       ...       ...  ...       ...       ...   \n",
       "attr5_3   0.201598  0.018610  0.002868  0.108400  ...  0.858673  0.174329   \n",
       "sinc5_3   0.125594 -0.035897 -0.002601  0.021372  ...  0.224796  0.608213   \n",
       "intel5_3  0.106791 -0.004632  0.003345  0.009585  ...  0.335831  0.288062   \n",
       "fun5_3    0.232412  0.016419  0.031795  0.096788  ...  0.394979  0.160204   \n",
       "amb5_3    0.030543  0.029174  0.050511  0.043115  ...  0.194495  0.135499   \n",
       "\n",
       "          intel3_3    fun3_3    amb3_3   attr5_3   sinc5_3  intel5_3  \\\n",
       "gender    0.011476 -0.153701 -0.066626 -0.133302 -0.277085  0.080227   \n",
       "idg      -0.060674 -0.041080 -0.005502  0.001764 -0.018915 -0.093206   \n",
       "condtn    0.061796  0.069298  0.027447  0.077571 -0.087502  0.051449   \n",
       "wave     -0.104562  0.053971  0.000520  0.092556 -0.001751  0.014611   \n",
       "round     0.022696  0.059530  0.013107  0.034647 -0.035242 -0.012896   \n",
       "...            ...       ...       ...       ...       ...       ...   \n",
       "attr5_3   0.421117  0.410789  0.235485  1.000000  0.190198  0.355876   \n",
       "sinc5_3   0.315857  0.180240  0.122856  0.190198  1.000000  0.498313   \n",
       "intel5_3  0.683871  0.240322  0.268646  0.355876  0.498313  1.000000   \n",
       "fun5_3    0.295997  0.771447  0.331533  0.412403  0.335823  0.262987   \n",
       "amb5_3    0.353093  0.429332  0.619087  0.194078  0.261307  0.422743   \n",
       "\n",
       "            fun5_3    amb5_3  \n",
       "gender   -0.065562  0.069091  \n",
       "idg      -0.061079 -0.145645  \n",
       "condtn    0.106486  0.123314  \n",
       "wave      0.088716  0.047841  \n",
       "round     0.104829  0.092951  \n",
       "...            ...       ...  \n",
       "attr5_3   0.412403  0.194078  \n",
       "sinc5_3   0.335823  0.261307  \n",
       "intel5_3  0.262987  0.422743  \n",
       "fun5_3    1.000000  0.379768  \n",
       "amb5_3    0.379768  1.000000  \n",
       "\n",
       "[183 rows x 183 columns]"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get correlation of all data\n",
    "df[num_cols].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "939cdc3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1], dtype=int64)"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Get unique values in gender\n",
    "np.unique(df['gender'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "89ba2572",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove the columns that remove from list of columns\n",
    "cols=list(cols)\n",
    "for i in ['undergra', 'mn_sat', 'tuition', 'income']:\n",
    "    cols.remove(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "4f543dec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gender         0\n",
       "idg            0\n",
       "condtn         0\n",
       "wave           0\n",
       "round          0\n",
       "            ... \n",
       "attr5_3     4496\n",
       "sinc5_3     4496\n",
       "intel5_3    4496\n",
       "fun5_3      4496\n",
       "amb5_3      4496\n",
       "Length: 187, dtype: int64"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#count of null values\n",
    "df[cols].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "daa9874d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with trail 1,2,3,4,5,6,7,8,9,10,11 we drop columns that have more than or equal 60% null values\n",
    "df=df.dropna(thresh=df.shape[0]*0.6,how='all',axis=1)\n",
    "test=test.dropna(thresh=test.shape[0]*0.6,how='all',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "a49ef998",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5909, 120)"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# trail 1,2,3,4,5,6,7 new shape for our data \n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "f67b6f67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gender      0\n",
       "idg         0\n",
       "condtn      0\n",
       "wave        0\n",
       "round       0\n",
       "           ..\n",
       "attr3_2     0\n",
       "sinc3_2     0\n",
       "intel3_2    0\n",
       "fun3_2      0\n",
       "amb3_2      0\n",
       "Length: 120, dtype: int64"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Replace the missing values with the most frequent values present in each column\n",
    "df=df.fillna(df.mode().iloc[0])\n",
    "test=test.fillna(df.mode().iloc[0])\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d7d5ad9",
   "metadata": {},
   "source": [
    "### Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "298a6c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split data to x,y\n",
    "x=df.drop('match',axis=1)\n",
    "y=df['match']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "025212a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'#with trail 1,2,3,4,5,6,7 we used Normalizing and selecting data\\nfrom sklearn.preprocessing import StandardScaler\\nt = preprocessing.normalize(x)\\ntst=preprocessing.normalize(test)\\nnames = x.columns.values.tolist()\\nx = pd.DataFrame(t, columns = names)\\ntst = StandardScaler().fit_transform(tst)'"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''#with trail 1,2,3,4,5,6,7 we used Normalizing and selecting data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "t = preprocessing.normalize(x)\n",
    "tst=preprocessing.normalize(test)\n",
    "names = x.columns.values.tolist()\n",
    "x = pd.DataFrame(t, columns = names)\n",
    "tst = StandardScaler().fit_transform(tst)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "6b0dc5e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#trail 8,9,10,11 we used StandardScaler without normalization:\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "x = scaler.fit_transform(x)\n",
    "#for test\n",
    "test=scaler.fit_transform(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7429d31e",
   "metadata": {},
   "source": [
    "#### LogisticRegression   modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "c16921b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import library for split \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression  \n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn import metrics\n",
    "#split data to train and validation and test 80,20,20 in orders\n",
    "X_both, X_test, y_both, y_test = train_test_split(x, y, test_size = 0.2, random_state = 42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_both, y_both, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "d8e29887",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy:  0.846723044397463\n"
     ]
    }
   ],
   "source": [
    "#trail9\n",
    "# trial2: DEFINE PARAMETER c take values logspace(-3,3,7) and penalty l1 lasso l2 ridge\n",
    "grid={\"C\":np.logspace(-3,3,20), \"penalty\":[\"l1\",\"l2\"],'solver': ['newton-cg', 'lbfgs', 'liblinear']}\n",
    "#define MODEL\n",
    "logreg=LogisticRegression()\n",
    "# trial 2:define evaluation  10 folds and three repeats.\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "#trial 2:define Grid search\n",
    "grid_search=GridSearchCV(logreg,grid,cv=cv)\n",
    "# execute search\n",
    "grid_search.fit(X_train,y_train)\n",
    "# predict the model\n",
    "y_pred = grid_search.predict(X_val)\n",
    "print(\"train accuracy: \",accuracy_score(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "ee978e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame()\n",
    "submission['id'] =v\n",
    "submission['match'] = grid_search.predict_proba(test)[:,1]\n",
    "submission.to_csv('sample_submission_walkthrough.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "57ffca0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy:  0.8382663847780126\n"
     ]
    }
   ],
   "source": [
    "# trial 3\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "#define MODEL\n",
    "model = LogisticRegression()\n",
    "# trial 3:define evaluation  10 folds and three repeats.\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "# trial 3: DEFINE PARAMETER c take values logspace(-3,3,7) and penalty l1 lasso l2 ridge\n",
    "space = dict()\n",
    "space['solver'] = ['newton-cg', 'lbfgs', 'liblinear']\n",
    "space['penalty'] = ['none', 'l1', 'l2', 'elasticnet']\n",
    "space['C']=np.logspace(-3,3,7)\n",
    "#define Random search with number of iteration 500 and random state 1\n",
    "search = RandomizedSearchCV(model, space, n_iter=500, scoring='accuracy', n_jobs=-1, cv=cv, random_state=1)\n",
    "# execute search\n",
    "result = search.fit(X_train,y_train)\n",
    "# predict the model\n",
    "y_pred = result.predict(X_val)\n",
    "print(\"train accuracy: \",accuracy_score(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cdc173a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame()\n",
    "submission['id'] =test['id']\n",
    "submission['match'] = result.predict_proba(test)[:,1]\n",
    "submission.to_csv('sample_submission_walkthrough1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9686d6dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install scikit-optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bbac50e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy:  0.8298097251585623\n"
     ]
    }
   ],
   "source": [
    "# trial 1\n",
    "from skopt import BayesSearchCV\n",
    "#define MODEL\n",
    "model = LogisticRegression()\n",
    "# define evaluation  10 folds and three repeats.\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=42)\n",
    "# trial 1: DEFINE PARAMETER c take values logspace(-3,3,7) and penalty l1 lasso l2 ridge\n",
    "space = dict()\n",
    "space['solver'] = ['newton-cg', 'lbfgs', 'liblinear']\n",
    "space['penalty'] = ['l2']\n",
    "space['C']=np.logspace(-3,3,7)\n",
    "## trial 1: define Bayes search with space an number of job2=-1\n",
    "search = BayesSearchCV(model, search_spaces=space, n_jobs=-1, cv=cv)\n",
    "# execute search\n",
    "result = search.fit(X_train,y_train)\n",
    "# predict the model\n",
    "y_pred = result.predict(X_val)\n",
    "print(\"train accuracy: \",accuracy_score(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "df79a5f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame()\n",
    "submission['id'] =test['id']\n",
    "submission['match'] = result.predict_proba(test)[:,1]\n",
    "submission.to_csv('sample_submission_walkthrough2.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f4608e8",
   "metadata": {},
   "source": [
    "### Decision Tree model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "06c2f796",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy:  0.7938689217758985\n"
     ]
    }
   ],
   "source": [
    "# trial 4,8\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "#define MODEL with random_state=0\n",
    "dtree= DecisionTreeClassifier(random_state=0)\n",
    "# execute search\n",
    "dtree.fit(X_train,y_train)\n",
    "# predict the model\n",
    "y_pred = dtree.predict(X_val)\n",
    "print(\"train accuracy: \",accuracy_score(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "7e16d5a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame()\n",
    "submission['id'] =v\n",
    "submission['match'] = dtree.predict_proba(test)[:,1]\n",
    "submission.to_csv('sample_submission_walkthrough8.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "aeb79fc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 25 folds for each of 361 candidates, totalling 9025 fits\n",
      "train accuracy:  0.7695560253699789\n"
     ]
    }
   ],
   "source": [
    "#trial 6\n",
    "#we used dict for paramters(dtreeparam_grid) that have max_depth range from 1 to 20, 'max_features' range from 1 to 20 with 'random_state'=42 \n",
    "dtreeparam_grid = {\n",
    "    'max_depth': np.arange(1,20),\n",
    "    'max_features': np.arange(1,20),\n",
    "    'random_state': [42]\n",
    "}\n",
    "#used Grid Search with dtreeparam_grid and  25 folder\n",
    "dtree_search = GridSearchCV(dtree, param_grid = dtreeparam_grid, refit = True, verbose = 1, cv=25)\n",
    "# execute search\n",
    "dtree_search.fit(X_train , y_train)\n",
    "# predict the model\n",
    "y_pred = dtree.predict(X_val)\n",
    "print(\"train accuracy: \",accuracy_score(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6ae14668",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame()\n",
    "submission['id'] =test['id']\n",
    "submission['match'] = dtree.predict_proba(test)[:,1]\n",
    "submission.to_csv('sample_submission_walkthrough5.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a24d741c",
   "metadata": {},
   "source": [
    "### Support Vector Machines  model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "6ed44213",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy:  0.8498942917547568\n"
     ]
    }
   ],
   "source": [
    "# trial 5,10\n",
    "from sklearn.svm import SVC\n",
    "#define MODEL \n",
    "svc = SVC(kernel=\"rbf\",probability=True)\n",
    "# execute search\n",
    "svc.fit(X_train, y_train)\n",
    "# predict the model\n",
    "y_pred = svc.predict(X_val)\n",
    "print(\"train accuracy: \",accuracy_score(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8db623b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame()\n",
    "submission['id'] =v\n",
    "submission['match'] = svc.predict_proba(test)[:,1]\n",
    "submission.to_csv('sample_submission_walkthrough9.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbe6d5c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 25 folds for each of 456 candidates, totalling 11400 fits\n"
     ]
    }
   ],
   "source": [
    "# trial 7\n",
    "#we used dict for paramters(svcparam_grid) that have 'kernel' =['poly','rbf','sigmoid'], degree range from 1 to 20 ,C:range from 0 to 4, 'gamma'=['scale', 'auto']\n",
    "svcparam_grid = {\n",
    "    'kernel': ['poly','rbf','sigmoid'],\n",
    "    'degree': np.arange(1,20),\n",
    "    'random_state':[42],\n",
    "    'C': np.arange(0,4),\n",
    "    'gamma':['scale', 'auto']\n",
    "}\n",
    "#used Grid Search with svcparam_grid and  25 folder\n",
    "svc_search = GridSearchCV(svc, param_grid = svcparam_grid, refit = True, verbose = 1, cv=25)\n",
    "# execute search\n",
    "svc_search.fit(X_train , y_train)\n",
    "# predict the model\n",
    "y_pred = svc.predict(X_val)\n",
    "print(\"train accuracy: \",accuracy_score(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25822b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame()\n",
    "submission['id'] =test['id']\n",
    "submission['match'] = svc_search.predict_proba(test)[:,1]\n",
    "submission.to_csv('sample_submission_walkthrough6.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bbbbf04",
   "metadata": {},
   "source": [
    "### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "0cb6cb83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy:  0.854122621564482\n"
     ]
    }
   ],
   "source": [
    "#trail 11 RandomForestClassifier with max_depth=30, random_state=20\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "#define MODEL \n",
    "clf = RandomForestClassifier(max_depth=30, random_state=20)\n",
    "# execute model\n",
    "clf.fit(X_train, y_train)\n",
    "# predict the model\n",
    "y_pred = clf.predict(X_val)\n",
    "print(\"train accuracy: \",accuracy_score(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "42e0b980",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame()\n",
    "submission['id'] =v\n",
    "submission['match'] = clf.predict_proba(test)[:,1]\n",
    "submission.to_csv('sample_submission_walkthrough10.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "232c7dce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gender         0\n",
       "idg            0\n",
       "condtn         0\n",
       "wave           0\n",
       "round          0\n",
       "            ... \n",
       "attr5_3     1866\n",
       "sinc5_3     1866\n",
       "intel5_3    1866\n",
       "fun5_3      1866\n",
       "amb5_3      1866\n",
       "Length: 190, dtype: int64"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5affbf1e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
